from flask import Flask, Response, jsonify, send_from_directory, render_template
import cv2
import numpy as np
from ultralytics import YOLO
import supervision as sv
import threading
import winsound
import os
import json
import time
from datetime import datetime
from collections import deque

app = Flask(__name__)

# CẤU HÌNH
VIDEO_SOURCE = r"C:\Users\LENOVO\Downloads\bandemtrom.mp4"
IMAGE_DIR = "static/images"
CLIP_DIR = "static/clips"
LOG_FILE = "history.json"

for d in [IMAGE_DIR, CLIP_DIR]:
    os.makedirs(d, exist_ok=True)

# --- AI ---
model = YOLO("yolo11n.pt")
tracker = sv.ByteTrack()
label_annotator = sv.LabelAnnotator()

# --- ROI ---
area_points = None
last_alert_time = 0
ALERT_COOLDOWN = 15

# --- VIDEO ---
cap = cv2.VideoCapture(VIDEO_SOURCE)
FPS_SRC = int(cap.get(cv2.CAP_PROP_FPS)) or 25

#  THỐNG KÊ
frame_times = deque(maxlen=30)

# GIẢM TẦN SUẤT YOLO
DETECT_EVERY = 3          # YOLO chạy mỗi 3 frame
frame_id = 0
last_detections = None


def play_alarm():
    winsound.Beep(2000, 500)


def save_clip_worker(filename, frames_snapshot):
    if not frames_snapshot:
        return
    path = os.path.join(CLIP_DIR, filename)
    h, w, _ = frames_snapshot[0].shape
    fourcc = cv2.VideoWriter_fourcc(*'vp80')
    out = cv2.VideoWriter(path, fourcc, FPS_SRC, (w, h))
    for f in frames_snapshot:
        out.write(f)
    out.release()


#  VẼ ROI
def setup_roi():
    global area_points
    points = []

    def click_event(event, x, y, flags, param):
        if event == cv2.EVENT_LBUTTONDOWN:
            points.append([x, y])
        elif event == cv2.EVENT_RBUTTONDOWN and points:
            points.pop()

    cv2.namedWindow("VE ROI - ENTER DE HOAN THANH")
    cv2.setMouseCallback("VE ROI - ENTER DE HOAN THANH", click_event)

    while True:
        ret, img = cap.read()
        if not ret:
            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
            continue

        img = cv2.resize(img, (640, 360))
        for p in points:
            cv2.circle(img, (p[0], p[1]), 5, (0, 0, 255), -1)
        if len(points) > 1:
            cv2.polylines(img, [np.array(points)], False, (0, 255, 255), 2)

        cv2.imshow("VE ROI - ENTER DE HOAN THANH", img)
        if cv2.waitKey(1) == 13 and len(points) >= 3:
            break

    area_points = np.array(points, np.int32)
    cv2.destroyAllWindows()


setup_roi()


# STREAM
def generate_stream():
    global last_alert_time, frame_id, last_detections
    clip_frames = []

    while True:
        start_time = time.time()
        frame_id += 1

        ret, frame = cap.read()
        if not ret:
            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
            continue

        frame = cv2.resize(frame, (640, 360))

        #  YOLO CHẠY GIÁN ĐOẠN
        if frame_id % DETECT_EVERY == 0:
            results = model(frame, verbose=False)[0]
            detections = sv.Detections.from_ultralytics(results)
            detections = detections[detections.class_id == 0]
            detections = tracker.update_with_detections(detections)
            last_detections = detections
        else:
            detections = last_detections

        if detections is None:
            continue

        current_alert = False

        for i in range(len(detections)):
            coords = detections.xyxy[i]
            cx = int((coords[0] + coords[2]) / 2)
            cy = int(coords[3])

            inside = cv2.pointPolygonTest(area_points, (cx, cy), False)

            if inside >= 0:
                current_alert = True
                color = (0, 0, 255)
                cv2.putText(
                    frame, "!!! XAM NHAP !!!",
                    (int(coords[0]), int(coords[1] - 10)),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2
                )
                threading.Thread(target=play_alarm, daemon=True).start()
            else:
                color = (0, 255, 0)

            cv2.rectangle(
                frame,
                (int(coords[0]), int(coords[1])),
                (int(coords[2]), int(coords[3])),
                color, 2
            )

        # ===== LƯU SỰ KIỆN =====
        now = time.time()
        if current_alert and (now - last_alert_time > ALERT_COOLDOWN):
            last_alert_time = now

            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            img_name = f"alert_{ts}.jpg"
            clip_name = f"clip_{ts}.webm"

            cv2.imwrite(os.path.join(IMAGE_DIR, img_name), frame)

            log_entry = {
                "id": f"ALARM_{int(now)}",
                "timestamp": datetime.now().strftime("%H:%M:%S - %d/%m/%Y"),
                "object": "Phát hiện xâm nhập",
                "video_clip": f"clips/{clip_name}",
                "thumbnail": f"images/{img_name}"
            }

            logs = []
            if os.path.exists(LOG_FILE):
                with open(LOG_FILE, "r", encoding="utf-8") as f:
                    logs = json.load(f)
            logs.append(log_entry)

            with open(LOG_FILE, "w", encoding="utf-8") as f:
                json.dump(logs, f, indent=4, ensure_ascii=False)

            threading.Thread(
                target=save_clip_worker,
                args=(clip_name, clip_frames.copy()),
                daemon=True
            ).start()
            clip_frames.clear()

        if current_alert:
            clip_frames.append(frame.copy())

        # HIỂN THỊ
        cv2.polylines(frame, [area_points], True, (0, 255, 0), 2)
        labels = [f"ID:{tid}" for tid in detections.tracker_id]
        frame = label_annotator.annotate(frame, detections, labels)

        #  FPS
        frame_time = time.time() - start_time
        frame_times.append(frame_time)
        fps = round(1 / (sum(frame_times) / len(frame_times)), 2)

        cv2.putText(
            frame, f"FPS: {fps}",
            (10, 20),
            cv2.FONT_HERSHEY_SIMPLEX, 0.6,
            (255, 255, 0), 2
        )

        _, buf = cv2.imencode(".jpg", frame, [cv2.IMWRITE_JPEG_QUALITY, 80])
        yield (b"--frame\r\nContent-Type: image/jpeg\r\n\r\n" +
               buf.tobytes() + b"\r\n")


#  FLASK
@app.route("/")
def index():
    return render_template("index.html")


@app.route("/video_feed")
def video_feed():
    return Response(generate_stream(),
                    mimetype="multipart/x-mixed-replace; boundary=frame")


@app.route("/get_logs")
def get_logs():
    if not os.path.exists(LOG_FILE):
        return jsonify([])
    with open(LOG_FILE, "r", encoding="utf-8") as f:
        return jsonify(json.load(f))


@app.route("/clips/<path:filename>")
def clips(filename):
    return send_from_directory(CLIP_DIR, filename)


@app.route("/images/<path:filename>")
def images(filename):
    return send_from_directory(IMAGE_DIR, filename)


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000, threaded=True)
